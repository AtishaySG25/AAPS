print(age_months)
# Create another copy that adds a bit of noise to the age (in years) variable
age_noisy = age_years + rnorm(n, mean = 0, sd = 4)
print(age_noisy)
# Simulate a population model for height as a function of age (in years)
height = 20 + 3*age_years + rnorm(n, mean = 0, sd = 10)
print(height)
plot(age_years, height)
plot(age_years, height)
height
age_years
plot(age_years, height)
# Create a dataframe with all the predictors and the response
hData = data.frame(age_years, age_months, age_noisy, height)
head(hData)
# Create a dataframe with all the predictors and the response
hData = data.frame(age_years, age_months, age_noisy, height)
head(hData)
model = lm(data = hData, height ~ age_years + age_months)
summary(model)
# A quick way to visualize the relationship between the response and individual predictors
pairs(hData)
# Calculate correlation matrix for all predictors
hData %>% select(-c(height))
#cormat =
# A quick way to visualize the relationship between the response and individual predictors
pairs(hData)
cormat
# Calculate correlation matrix for all predictors
cormat = cor(hData %>% select(-c(height)))
cormat
# Calculate correlation matrix for all predictors
cormat = round(cor(hData %>% select(-c(height))), 2)
cormat
# Set lower-triangular part of correlation matrix to NA
cormat[lower.tri(cormat)] = NA
print(cormat)
# Melt the correlation matrix
melt(cormat)
print(cormat)
melt(cormat)
# Visualize the correlation matrix using ggplot
p = ggplot() + geom_tile(color = 'white') +
coord_fixed() +
scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation')
p
# Visualize the correlation matrix using ggplot
p = ggplot() + geom_tile(color = 'white') +
coord_fixed() +
scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation')
p
p
# Visualize the correlation matrix using ggplot
p = ggplot() + geom_tile(color = 'white') +
coord_fixed() +
scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation')
p
# Visualize the correlation matrix using ggplot
p = ggplot() + geom_tile(color = 'white') +
coord_fixed() +
scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation')
p
# Visualize the correlation matrix using ggplot
p = ggplot() + geom_tile(color = 'white') +
coord_fixed() +
scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation')
p
# Visualize the correlation matrix using ggplot
p = ggplot() + geom_tile(color = 'white') +
coord_fixed() +
scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation')
p
# Visualize the correlation matrix using ggplot
p = ggplot() + geom_tile(color = 'white') +
coord_fixed() +
scale_fill_gradient2(low = 'blue', high = 'red', mid = 'white', midpoint = 0, limit = c(-1, 1), space = 'Lab', name = 'Correlation')
p
dbinom(8, 10, 0.5)
dbinom(7, 10, 0.5)
1-pbinom(6, 10, 0.5)
1-pbinom(7, 10, 0.5)
1-pbinom(8, 10, 0.5)
setwd("D:/OneDrive - Manipal Academy of Higher Education/EvenSemester2024/AML5201/Codes/BDA")
# Load essential libraries
library(ggplot2)
library(dplyr)
library(car)
library(glmnet)
# Load essential libraries
library(ggplot2)
library(dplyr)
library(car)
library(glmnet)
# Load the house price dataset
hData = read.csv('../Data/houseprices_cleaned.csv', header = TRUE, stringsAsFactors = FALSE, na.strings = c("", 'Not available', 'NA', 'missing'))
str(hData)
# Convert 'locality', 'facing' and 'parking' columns to factors
categorical_cols = c('locality', 'facing', 'parking')
hData[categorical_cols] = lapply(hData[categorical_cols], as.factor)
str(hData)
# Load the house price dataset
hData = read.csv('../Data/houseprices_cleaned.csv', header = TRUE, stringsAsFactors = FALSE, na.strings = c("", 'Not available', 'NA', 'missing'))
str(hData)
# Convert 'locality', 'facing' and 'parking' columns to factors
categorical_cols = c('locality', 'facing', 'parking')
hData[categorical_cols] = lapply(hData[categorical_cols], as.factor)
str(hData)
# Continuous columns
continuous_cols = setdiff(colnames(hData), categorical_cols)
# Fraction of NAs in each column of the data frame
hData_NA = setNames(stack(sapply(hData, function(x){(sum(is.na(x))/length(x))*100}))[2:1], c('Feature','Value'))
p = ggplot(data = hData_NA, aes(x = Feature, y = Value)) +
geom_bar(stat = 'identity', fill = 'steelblue', width = 0.3) +
theme(text = element_text(size = 14, face = 'bold'),
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
xlab('') + ylab('Percentage') +
ggtitle('Percentage of NAs across all features')
p
# Add NA as a factor level for categorical columns
hData[categorical_cols] = lapply(hData[categorical_cols], addNA)
str(hData)
# Make a histogram of rent values
p = ggplot(data = hData) +
geom_histogram(aes(x = rent, y = after_stat(count)), breaks = seq(mean(hData$rent)-4*sd(hData$rent), mean(hData$rent)+4*sd(hData$rent), by = 25000), color = 'black', fill = 'blue') +
labs(x = 'Rent', y = 'Frequency')  +
theme(axis.text = element_text(size = 8),
axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.title = element_text(size = 10, face = "bold"))  +
ggtitle('Histogram of house rents')
p
# Build a linear model to predict price per square feet as a function of rent
model = lm(data = hData, price_per_sqft ~ rent)
summary(model)
# Make a histogram of transformed rent values
hData['logrent'] = log(hData['rent'])
p = ggplot(data = hData) +
geom_histogram(aes(x = logrent, y = after_stat(count)), breaks = seq(mean(hData$logrent)-4*sd(hData$logrent), mean(hData$logrent)+4*sd(hData$logrent), by = 0.5), color = 'black', fill = 'blue') +
labs(x = 'Rent', y = 'Frequency')  +
theme(axis.text = element_text(size = 8),
axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.title = element_text(size = 10, face = "bold"))  +
ggtitle('Histogram of log of house rents')
p
# Build a linear model to predict price per square feet as a function of logrent
model = lm(data = hData, price_per_sqft ~ logrent)
summary(model)
# Build a linear model to predict log of price per square feet as a function of logrent
hData['logprice_per_sqft'] = log(hData['price_per_sqft'])
model = lm(data = hData, logprice_per_sqft ~ logrent)
summary(model)
# Build a linear model to predict sqrt of price per square feet as a function of logrent
hData['sqrtprice_per_sqft'] = sqrt(hData['price_per_sqft'])
model = lm(data = hData, sqrtprice_per_sqft ~ logrent)
summary(model)
# Build a linear model to predict sqrt of price per sqft as a function of area and logrent
model = lm(data = hData, sqrtprice_per_sqft ~ area + logrent)
summary(model)
# Build a linear model to predict sqrt of price per sqft as a function of logarea and logrent
hData['logarea'] = log(hData['area'])
model = lm(data = hData, sqrtprice_per_sqft ~ logarea + logrent)
summary(model)
# Build a linear model to predict sqrt of price per sqft as a function of logarea, logrent, and locality
model = lm(data = hData, sqrtprice_per_sqft ~ logarea + logrent + locality)
summary(model)
# Build a linear model to predict price per sqft as a function of logarea, logrent, locality, BHK, bathrooms, facing, and parking
model = lm(data = hData, sqrtprice_per_sqft ~ logarea + logrent + locality + BHK + bathrooms + facing + parking)
summary(model)
# Build a linear model to predict sqrt of price per sqft as a function of logarea, logrent, and locality
model = lm(data = hData, sqrtprice_per_sqft ~ logarea + logrent + locality)
summary(model)
continuous_cols
paste0('scaled_', continuous_cols)
lapply(hData[continuous_cols], scale)
# Create new columns corresponding to scaled versions of the continuous columns
hData[paste0('scaled_', continuous_cols)] = lapply(hData[continuous_cols], scale)
str(hData)
# Build a linear model to predict scaled price per sqft as a function of scaled area and scaled rent
model = lm(data = hData, scaled_price_per_sqft ~ scaled_area + caled_rent)
# Build a linear model to predict scaled price per sqft as a function of scaled area and scaled rent
model = lm(data = hData, scaled_price_per_sqft ~ scaled_area + scaled_rent)
summary(model)
# Build a linear model to predict scaled price per sqft as a function of scaled area and scaled rent. Compare this with the model built using unscaled data: that is, predict price per sqft as a function of area and rent. Does scaling help?
model = lm(data = hData, scaled_price_per_sqft ~ scaled_area + scaled_rent)
summary(model)
model = lm(data = hData, price_per_sqft ~ area + rent)
summary(model)
# Build a linear model to predict scaled price per sqft as a function of scaled area and scaled rent. Compare this with the model built using unscaled data: that is, predict price per sqft as a function of area and rent. Does scaling help?
model = lm(data = hData, scaled_price_per_sqft ~ scaled_area + scaled_rent)
summary(model)
model = lm(data = hData, price_per_sqft ~ area + rent)
summary(model)
# Build a linear model to predict scaled price per sqft as a function of scaled area, scaled rent and locality. Compare this with the model built using unscaled data: that is, predict price per sqft as a function of area, rent, and locality. Does scaling help?
model = lm(data = hData, scaled_price_per_sqft ~ scaled_area + scaled_rent + locality)
summary(model)
model = lm(data = hData, price_per_sqft ~ area + rent + locality)
summary(model)
# Split data into train (80%) and test (20%) sets
ind = sample(nrow(hData), size = floor(.8*nrow(hData)), replace = F)
sample(nrow(hData), size = floor(.8*nrow(hData)), replace = F)
# Split data into train (80%) and test (20%) sets
ind = sample(nrow(hData), size = floor(.8*nrow(hData)), replace = F)
hData_train = hData[ind, ]
hData_test = hData[-ind, ]
# Rebuild a linear model to predict sqrt of price per sqft as a function of logarea, logrent, and locality which we will evaluate using a train-test split of the dataset
model = lm(data = hData, sqrtprice_per_sqft ~ logarea + logrent + locality)
summary(model)
# Split data into train (80%) and test (20%) sets
ind = sample(nrow(hData), size = floor(.8*nrow(hData)), replace = F)
hData_train = hData[ind, ]
hData_test = hData[-ind, ]
# Calculate RMSE (root-mean-squared-error) on train data
train_error = sqrt(mean((hData_train$sqrtprice_per_sqft - predict(model, hData_train))^2))
# Calculate RMSE (root-mean-squared-error) on test data
test_error = sqrt(mean((hData_test$sqrtprice_per_sqft - predict(model, hData_test))^2))
# Calculate RMSE (root-mean-squared-error) on train data
train_error = sqrt(mean((hData_train$sqrtprice_per_sqft - predict(model, hData_train))^2))
# Calculate RMSE (root-mean-squared-error) on test data
test_error = sqrt(mean((hData_test$sqrtprice_per_sqft - predict(model, hData_test))^2))
print(train_error)
print(test_error)
# Calculate RMSE (root-mean-squared-error) on train data
train_error = sqrt(mean((hData_train$sqrtprice_per_sqft - predict(model, hData_train))^2))
# Calculate RMSE (root-mean-squared-error) on test data
test_error = sqrt(mean((hData_test$sqrtprice_per_sqft - predict(model, hData_test))^2))
print(train_error)
print(test_error)
# Split data into train (80%) and test (20%) sets
ind = sample(nrow(hData), size = floor(.8*nrow(hData)), replace = F)
hData_train = hData[ind, ]
hData_test = hData[-ind, ]
# Calculate RMSE (root-mean-squared-error) on train data
train_error = sqrt(mean((hData_train$sqrtprice_per_sqft - predict(model, hData_train))^2))
# Calculate RMSE (root-mean-squared-error) on test data
test_error = sqrt(mean((hData_test$sqrtprice_per_sqft - predict(model, hData_test))^2))
print(train_error)
print(test_error)
# Split data into train (80%) and test (20%) sets
ind = sample(nrow(hData), size = floor(.8*nrow(hData)), replace = F)
hData_train = hData[ind, ]
hData_test = hData[-ind, ]
# Calculate RMSE (root-mean-squared-error) on train data
train_error = sqrt(mean((hData_train$sqrtprice_per_sqft - predict(model, hData_train))^2))
# Calculate RMSE (root-mean-squared-error) on test data
test_error = sqrt(mean((hData_test$sqrtprice_per_sqft - predict(model, hData_test))^2))
print(train_error)
print(test_error)
# Split data into train (80%) and test (20%) sets
ind = sample(nrow(hData), size = floor(.8*nrow(hData)), replace = F)
hData_train = hData[ind, ]
hData_test = hData[-ind, ]
# Calculate RMSE (root-mean-squared-error) on train data
train_error = sqrt(mean((hData_train$sqrtprice_per_sqft - predict(model, hData_train))^2))
# Calculate RMSE (root-mean-squared-error) on test data
test_error = sqrt(mean((hData_test$sqrtprice_per_sqft - predict(model, hData_test))^2))
print(train_error)
print(test_error)
# Load essential libraries
library(ggplot2)
library(dplyr)
library(car)
library(glmnet)
# Load the house price dataset
hData = read.csv('../Data/houseprices_cleaned.csv', header = TRUE, stringsAsFactors = FALSE, na.strings = c("", 'Not available', 'NA', 'missing'))
str(hData)
# Convert 'locality', 'facing' and 'parking' columns to factors
categorical_cols = c('locality', 'facing', 'parking')
hData[categorical_cols] = lapply(hData[categorical_cols], as.factor)
str(hData)
# Continuous columns
continuous_cols = setdiff(colnames(hData), categorical_cols)
# Fraction of NAs in each column of the data frame
hData_NA = setNames(stack(sapply(hData, function(x){(sum(is.na(x))/length(x))*100}))[2:1], c('Feature','Value'))
p = ggplot(data = hData_NA, aes(x = Feature, y = Value)) +
geom_bar(stat = 'identity', fill = 'steelblue', width = 0.3) +
theme(text = element_text(size = 14, face = 'bold'),
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
xlab('') + ylab('Percentage') +
ggtitle('Percentage of NAs across all features')
p
# Add NA as a factor level for categorical columns
hData[categorical_cols] = lapply(hData[categorical_cols], addNA)
str(hData)
# Make a histogram of rent values
p = ggplot(data = hData) +
geom_histogram(aes(x = rent, y = after_stat(count)), breaks = seq(mean(hData$rent)-4*sd(hData$rent), mean(hData$rent)+4*sd(hData$rent), by = 25000), color = 'black', fill = 'blue') +
labs(x = 'Rent', y = 'Frequency')  +
theme(axis.text = element_text(size = 8),
axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.title = element_text(size = 10, face = "bold"))  +
ggtitle('Histogram of house rents')
p
# Build a linear model to predict price per square feet as a function of rent
model = lm(data = hData, price_per_sqft ~ rent)
summary(model)
# Make a histogram of transformed rent values
hData['logrent'] = log(hData['rent'])
p = ggplot(data = hData) +
geom_histogram(aes(x = logrent, y = after_stat(count)), breaks = seq(mean(hData$logrent)-4*sd(hData$logrent), mean(hData$logrent)+4*sd(hData$logrent), by = 0.5), color = 'black', fill = 'blue') +
labs(x = 'Rent', y = 'Frequency')  +
theme(axis.text = element_text(size = 8),
axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.title = element_text(size = 10, face = "bold"))  +
ggtitle('Histogram of log of house rents')
p
# Build a linear model to predict price per square feet as a function of logrent
model = lm(data = hData, price_per_sqft ~ logrent)
summary(model)
hist(hData$price_per_sqft)
hist(log(hData$price_per_sqft))
hist(sqrt(hData$price_per_sqft))
# Build a linear model to predict sqrt of price per square feet as a function of logrent
hData['sqrtprice_per_sqft'] = sqrt(hData['price_per_sqft'])
model = lm(data = hData, sqrtprice_per_sqft ~ logrent)
summary(model)
# Build a linear model to predict sqrt of price per sqft as a function of area and logrent
model = lm(data = hData, sqrtprice_per_sqft ~ area + logrent)
summary(model)
# Build a linear model to predict sqrt of price per sqft as a function of logarea and logrent
hData['logarea'] = log(hData['area'])
model = lm(data = hData, sqrtprice_per_sqft ~ logarea + logrent)
summary(model)
# Build a linear model to predict sqrt of price per sqft as a function of logarea, logrent, and locality
model = lm(data = hData, sqrtprice_per_sqft ~ logarea + logrent + locality)
summary(model)
# Load essential libraries
library(ggplot2)
library(dplyr)
library(car)
library(glmnet)
# Load essential libraries
library(ggplot2)
library(dplyr)
library(car)
library(glmnet)
library(reshape)
colnames(hData)
# Create new columns corresponding to scaled versions of the continuous columns
hData[paste0('scaled_', continuous_cols)] = lapply(hData[continuous_cols], scale)
str(hData)
colnames(hData)
X = hData[c('locality', 'bathrooms', 'parking', 'scaled_rent', 'scaled_area', 'scaled_BHK', 'scaled_bathroom')]
X = hData[c('locality', 'facing', 'parking', 'scaled_rent', 'scaled_area', 'scaled_BHK', 'scaled_bathrooms')]
X
# Lasso regression using glmnet
X = hData[c('locality', 'facing', 'parking', 'scaled_rent', 'scaled_area', 'scaled_BHK', 'scaled_bathrooms')]
y = hData['scaled_price_per_sqft']
# Set lambda sequence
lambdas = 10^seq(-2, 1.5, 0.1)
lasso.fit = glmnet(X, y, lambda = lambdas)
setwd("D:/OneDrive/Manipal/Courses/OfficeOfOnlineEducation/MDS5201/Codes")
library(ggplot2)
library(dplyr)
library(lars)
# Load diabetes data
data('diabetes', package = 'lars')
# Boxplot excluding the ID column
ggplot(data = melt(X), aes(x = factor(X2), y = value)) +
geom_boxplot()
# Boxplot excluding the ID column
ggplot(data = melt(X), aes(x = factor(X2), y = value)) +
geom_boxplot()
library(ggplot2)
library(dplyr)
library(lars)
# Load diabetes data
data('diabetes', package = 'lars')
install.packages('lars')
# Load diabetes data
data('diabetes', package = 'lars')
str(diabetes)
colnames(diabetes)
# slot x has the scaled predictor values corresponding to 10 baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements n = 442 diabetes patients,
# slot y is the response variable, a quantitative measure of disease progression one year after baseline
X = diabetes$x
y = diabetes$y
class(X) = NULL
# Boxplot excluding the ID column
ggplot(data = melt(X), aes(x = factor(X2), y = value)) +
geom_boxplot()
library(ggplot2)
library(dplyr)
library(lars)
library(glmnet)
library(reshape)
install.packages('reshape2')
install.packages('reshape')
library(ggplot2)
library(dplyr)
library(lars)
library(glmnet)
library(reshape)
# Load diabetes data
data('diabetes', package = 'lars')
str(diabetes)
colnames(diabetes)
# slot x has the scaled predictor values corresponding to 10 baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements n = 442 diabetes patients,
# slot y is the response variable, a quantitative measure of disease progression one year after baseline
X = diabetes$x
y = diabetes$y
class(X) = NULL
# Boxplot excluding the ID column
ggplot(data = melt(X), aes(x = factor(X2), y = value)) +
geom_boxplot()
str(X)
str(y)
typeof(X)
class(X)
setwd("D:/OneDrive - Manipal Academy of Higher Education/EvenSemester2024/AML5201/Codes/BDA")
# Lasso regression using glmnet
X = hData[c('locality', 'facing', 'parking', 'scaled_rent', 'scaled_area', 'scaled_BHK', 'scaled_bathrooms')]
y = hData['scaled_price_per_sqft']
# Set lambda sequence
lambdas = 10^seq(-2, 1.5, 0.1)
lasso.fit = glmnet(X, y, lambda = lambdas)
str(X)
as.matrix(X)
str(as.matrix(X))
X = model.matrix(scaled_price_per_sqft ~ locality + facing + parking + scaled_rent + scaled_area + scaled_BHK + scaled_bathrooms, hData %>% select(scaled_price_per_sqft, locality, facing, parking, scaled_rent, scaled_area, scaled_BHK, scaled_bathrooms))
X
X[:, 2:]
X[, 2:]
X[, 2:end]
X[, 2:END]
X[, 2:]
X[, c(2:)]
X[, c(2:ncol(X))]
# Lasso regression using glmnet
X = model.matrix(scaled_price_per_sqft ~ locality + facing + parking + scaled_rent + scaled_area + scaled_BHK + scaled_bathrooms, hData %>% select(scaled_price_per_sqft, locality, facing, parking, scaled_rent, scaled_area, scaled_BHK, scaled_bathrooms))
X = X[, c(2:ncol(X))]
y = hData[['scaled_price_per_sqft']]
# Set lambda sequence
lambdas = 10^seq(-2, 1.5, 0.1)
lasso.fit = glmnet(X, y, lambda = lambdas)
# Print the summary of the glmnet path
print(lasso.fit)
# Visualize the path of the coefficients
plot(lasso.fit, label = TRUE)
# Obtain model coefficients for specific lambda
coef(lasso.fit, s = lambdas[length(lambdas)])
# Lasso regression using glmnet
X = model.matrix(scaled_price_per_sqft ~ locality + facing + parking + scaled_rent + scaled_area + scaled_BHK + scaled_bathrooms, hData %>% select(scaled_price_per_sqft, locality, facing, parking, scaled_rent, scaled_area, scaled_BHK, scaled_bathrooms))
X = X[, c(2:ncol(X))]
y = hData[['scaled_price_per_sqft']]
# Set lambda sequence
lambdas = 10^seq(-2, 1.5, 0.1)
lasso.fit = glmnet(X, y, lambda = lambdas)
# Print the summary of the glmnet path
print(lasso.fit)
# Visualize the path of the coefficients
plot(lasso.fit, label = TRUE)
# Obtain model coefficients for specific lambda
coef(lasso.fit, s = lambdas[length(lambdas)])
# Lasso regression using glmnet
X = model.matrix(scaled_price_per_sqft ~ locality + facing + parking + scaled_rent + scaled_area + scaled_BHK + scaled_bathrooms, hData %>% select(scaled_price_per_sqft, locality, facing, parking, scaled_rent, scaled_area, scaled_BHK, scaled_bathrooms))
X = X[, c(2:ncol(X))]
y = hData[['scaled_price_per_sqft']]
# Set lambda sequence
#lambdas = 10^seq(-2, 1.5, 0.1)
lambdas = c(0.1)
lasso.fit = glmnet(X, y, lambda = lambdas)
# Print the summary of the glmnet path
print(lasso.fit)
# Visualize the path of the coefficients
plot(lasso.fit, label = TRUE)
# Obtain model coefficients for specific lambda
coef(lasso.fit, s = lambdas[length(lambdas)])
# Lasso regression using glmnet
X = model.matrix(scaled_price_per_sqft ~ locality + facing + parking + scaled_rent + scaled_area + scaled_BHK + scaled_bathrooms, hData %>% select(scaled_price_per_sqft, locality, facing, parking, scaled_rent, scaled_area, scaled_BHK, scaled_bathrooms))
X = X[, c(2:ncol(X))]
y = hData[['scaled_price_per_sqft']]
# Set lambda sequence
#lambdas = 10^seq(-2, 1.5, 0.1)
lambdas = c(1.0)
lasso.fit = glmnet(X, y, lambda = lambdas)
# Print the summary of the glmnet path
print(lasso.fit)
# Visualize the path of the coefficients
plot(lasso.fit, label = TRUE)
# Obtain model coefficients for specific lambda
coef(lasso.fit, s = lambdas[length(lambdas)])
# Lasso regression using glmnet
X = model.matrix(scaled_price_per_sqft ~ locality + facing + parking + scaled_rent + scaled_area + scaled_BHK + scaled_bathrooms, hData %>% select(scaled_price_per_sqft, locality, facing, parking, scaled_rent, scaled_area, scaled_BHK, scaled_bathrooms))
X = X[, c(2:ncol(X))]
y = hData[['scaled_price_per_sqft']]
# Set lambda sequence
#lambdas = 10^seq(-2, 1.5, 0.1)
lambdas = c(0.01)
lasso.fit = glmnet(X, y, lambda = lambdas)
# Print the summary of the glmnet path
print(lasso.fit)
# Visualize the path of the coefficients
plot(lasso.fit, label = TRUE)
# Obtain model coefficients for specific lambda
coef(lasso.fit, s = lambdas[length(lambdas)])
# Lasso regression using glmnet
X = model.matrix(scaled_price_per_sqft ~ locality + facing + parking + scaled_rent + scaled_area + scaled_BHK + scaled_bathrooms, hData %>% select(scaled_price_per_sqft, locality, facing, parking, scaled_rent, scaled_area, scaled_BHK, scaled_bathrooms))
X = X[, c(2:ncol(X))]
y = hData[['scaled_price_per_sqft']]
# Set lambda sequence
#lambdas = 10^seq(-2, 1.5, 0.1)
lambdas = c(0.5)
lasso.fit = glmnet(X, y, lambda = lambdas)
# Print the summary of the glmnet path
print(lasso.fit)
# Visualize the path of the coefficients
plot(lasso.fit, label = TRUE)
# Obtain model coefficients for specific lambda
coef(lasso.fit, s = lambdas[length(lambdas)])
